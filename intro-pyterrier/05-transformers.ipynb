{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introduction to PyTerrier\n",
    "\n",
    "_DSAIT4050: Information retrieval lecture, TU Delft_\n",
    "\n",
    "**Part 5: Transformers**\n",
    "\n",
    "This notebook introduces PyTerrier _transformers_ (not to be confused with [neural transformer models](<https://en.wikipedia.org/wiki/Transformer_(deep_learning_architecture)>)). We'll learn about the different types of data frames that PyTerrier uses and how the transformers operate on them.\n",
    "\n",
    "To run everything in this notebook, you'll need [pyterrier-caching](https://pyterrier.readthedocs.io/en/latest/ext/pyterrier-caching/index.html) and [pyspellchecker](https://github.com/barrust/pyspellchecker) installed:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "shellscript"
    }
   },
   "outputs": [],
   "source": [
    "pip install python-terrier==0.12.1 pyterrier-caching==0.3.0 pyspellchecker"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyterrier as pt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the following, we'll illustrate the different kinds of transformers and data frames using examples. Note that we're only scratching the surface here, so **make sure to have a look at the [documentation](https://pyterrier.readthedocs.io/)**!\n",
    "\n",
    "We'll use the `nfcorpus` dataset:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = pt.get_dataset(\"irds:nfcorpus/test\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For this task we'll need an index with blocks (i.e., positional information), so we need to create a new one, setting `blocks=True`. Since memory indexes do not support blocks at the moment, we'll create one on disk:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "\n",
    "idx_path = Path.cwd() / \"05_data\" / \"nfcorpus_index_with_blocks\"\n",
    "pt.index.IterDictIndexer(\n",
    "    str(idx_path),\n",
    "    blocks=True,\n",
    ").index(dataset.get_corpus_iter(), fields=[\"title\", \"abstract\", \"url\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data format\n",
    "\n",
    "Recall that the queries (topics) of a dataset can be accessed using the `get_topics` method. For this dataset, there are multiple variants; we choose `title`:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "queries = dataset.get_topics(variant=\"title\")\n",
    "queries"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In general, PyTerrier represents all data as `pandas.DataFrame` objects.\n",
    "\n",
    "The method above outputs a data frame with two columns, `qid` and `query`. In PyTerrier, data frames of this format are referred to as _data type_ `Q`, and they essentially represent a set of queries, each of which has a unique identifier. In fact, we have already constructed our own `Q` data frames in the scaffolding project.\n",
    "\n",
    "There are some other data types, and we will introduce them throughout the rest of this series. You can find an overview [here](https://pyterrier.readthedocs.io/en/latest/datamodel.html).\n",
    "\n",
    "## Transformers\n",
    "\n",
    "_Transformers_ directly operate on these data frames; in other words, a transformer takes as input a data frame of some type and outputs another data frame (of the same or another type). We'll take a look at several pre-implemented transformers in this notebook.\n",
    "\n",
    "### Retrieval transformers\n",
    "\n",
    "Retrievers are the most common transformers, and we have already used them plenty throughout this introductory series. For example, let's take a BM25 model as before:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "index = pt.IndexFactory.of(str(idx_path))\n",
    "bm25 = pt.terrier.Retriever(index, wmodel=\"BM25\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This transformer consumes data of type `Q` and returns data of type `R` (i.e., columns `qid`, `docno`, `score`, `rank`), which corresponds to a ranking. The transformation can be invoked by calling the `transform` method:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bm25.transform(queries)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that our result is actually a superset of `R` (we have an additional column, `query`). In general, data frames may have more columns than a specific transformer requires, but they can still be used.\n",
    "\n",
    "Alternatively, the transformer can be called directly, as we have done so far, which gives the same result:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bm25(queries)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Furthermore, transformers implement the `search` method, which processes a single query:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bm25.search(\"what is the meaning of life\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Query rewriting transformers\n",
    "\n",
    "You have already experimented with query rewriting in the scaffolding project. PyTerrier implements several transformers that rewrite queries.\n",
    "\n",
    "The simplest one is the _sequential dependence model_:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "sdm = pt.rewrite.SequentialDependence()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "SDM requires positional information in the index (that's why we needed to set a flag during indexing). More information about SDM can be found [here](https://pyterrier.readthedocs.io/en/latest/rewrite.html#sequentialdependence).\n",
    "\n",
    "It operates solely on the queries themselves; in other words, both input and output are data frames of type `Q`:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sdm(queries)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this case, the `query` column contains the new (rewritten) queries, while the original queries are retained in the `query_0` column.\n",
    "\n",
    "#### Query expansion\n",
    "\n",
    "_Query expansion_ differs from standard query rewriting in that it operates on queries **and** corresponding relevant documents (these need to be retrieved based on the original queries prior to the expansion). This is also known as _pseudo relevance feedback_ (PRF). A popular PRF model is _RM3_:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "rm3 = pt.rewrite.RM3(index)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since RM3 requires a set of documents for each query, its input type needs to be `R`. Consequently, we can use the result of our retriever as an input for the PRF model:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rm3(bm25(queries))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pipelines\n",
    "\n",
    "You probably noticed that the transformers we've seen so far are mostly designed to work in sequence; for example, reformulating queries alone is pointless without an actual retrieval step afterwards.\n",
    "\n",
    "This is where _pipelines_ come into play. PyTerrier implements the `>>` operator to build sequences of transformers. Let's build a simple pipeline that applies SDM and then retrieves documents using BM25:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "pl_sdm = sdm >> bm25"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can now use this pipeline like any other transformer:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pl_sdm(queries)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's compare SDM and RM3 in terms of performance.\n",
    "\n",
    "First, we create a pipeline for RM3:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "pl_rm3 = bm25 >> rm3 >> bm25"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can run an experiment to evaluate and compare both of these pipelines. We'll also include standalone BM25:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyterrier.measures import MAP, nDCG\n",
    "\n",
    "pt.Experiment(\n",
    "    [bm25, pl_sdm, pl_rm3],\n",
    "    queries,\n",
    "    dataset.get_qrels(),\n",
    "    names=[\"BM25\", \"SDM >> BM25\", \"BM25 >> RM3 >> BM25\"],\n",
    "    eval_metrics=[MAP, nDCG @ 10],\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Caching\n",
    "\n",
    "Caching the outputs of a transformer can be useful when it is part of a pipeline that is executed multiple times. PyTerrier supports caching via a plugin, `pyterrier-caching`, which we have already installed above.\n",
    "\n",
    "Let's time our BM25 retriever without caching first:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%timeit bm25(queries)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can create a cached version of this retriever using `RetrieverCache`. The results are cached in a directory of our choosing (`bm25_cache`):\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyterrier_caching import RetrieverCache\n",
    "\n",
    "bm25_cached = RetrieverCache(Path.cwd() / \"05_data\" / \"bm25_cache\", bm25)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can compare the latency of our cached retriever with the uncached version:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%timeit bm25_cached(queries)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "An overview of the available caches can be found in the [documentation](https://pyterrier.readthedocs.io/en/latest/ext/pyterrier-caching/index.html).\n",
    "\n",
    "**Important**: When you use caching, make sure to clear the cache when you make changes to the transformers you cached. Otherwise, you might get unexpected results.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Operators\n",
    "\n",
    "There are a number of _operators_ that can be applied to transformers within pipelines. We've already seen the `>>` operator. Here, we'll look at a few more selected operators. You can find the complete list [here](https://pyterrier.readthedocs.io/en/latest/operators.html).\n",
    "\n",
    "#### Rank cutoff\n",
    "\n",
    "The `%` operator limits how many documents per query are kept (the lowest-scoring ones are removed). For example, we may want to consider only a single document for RM3:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pl_rm3_1doc = (bm25 % 1) >> rm3 >> bm25\n",
    "\n",
    "pt.Experiment(\n",
    "    [pl_rm3, pl_rm3_1doc],\n",
    "    queries,\n",
    "    dataset.get_qrels(),\n",
    "    names=[\"RM3\", \"RM3 (1 document)\"],\n",
    "    eval_metrics=[MAP, nDCG @ 10],\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Combining rankings\n",
    "\n",
    "The `+` and `*` operators can be used to linearly combine two transformers that output rankings (data type `R`). For example, we can use two different retrievers and combine them as follows:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf_idf = pt.terrier.Retriever(index, wmodel=\"TF_IDF\")\n",
    "\n",
    "pt.Experiment(\n",
    "    [tf_idf, bm25, 2 * tf_idf + bm25],\n",
    "    queries,\n",
    "    dataset.get_qrels(),\n",
    "    names=[\"TF-IDF\", \"BM25\", \"2 * TF-IDF + BM25\"],\n",
    "    eval_metrics=[MAP, nDCG @ 10],\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that the operations are applied to the scores computed by the retrievers. If a document is missing for one of the retrievers, a score of `0` is used.\n",
    "\n",
    "### Compiling pipelines\n",
    "\n",
    "Pipelines can be compiled. The compilation may improve the efficiency for certain operations. For example, consider the following:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "pl = bm25 % 3\n",
    "pl_compiled = pl.compile()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's time them both:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%timeit pl(queries)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%timeit pl_compiled(queries)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Custom transformers\n",
    "\n",
    "PyTerrier makes it easy for you to implement your own custom transformers. In fact, we've used a custom query transformer under the hood for the scaffolding project.\n",
    "\n",
    "### `apply` functions\n",
    "\n",
    "[`pyterrier.apply`](https://pyterrier.readthedocs.io/en/latest/apply.html) allows for applying a custom function to each row of a data frame. There are many `apply` functions, each of which focuses on different data types. An overview can be found [here](https://pyterrier.readthedocs.io/en/latest/apply.html#module-pyterrier.apply).\n",
    "\n",
    "Let's implement one that reformulates the query to sound a bit nicer:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ask_nicely = pt.apply.query(\n",
    "    lambda row: \"please find some information about \" + row[\"query\"]\n",
    ")\n",
    "ask_nicely(queries)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Extending `pyterrier.Transformer`\n",
    "\n",
    "More complex transformers can be implemented by extending the base class directly.\n",
    "\n",
    "Here, we implement a transformer that naively corrects supposed spelling mistakes using a spell checking library. In order to do this, we only need to implement the `transform` method. We adapt the behavior of the other query rewriters and retain the original formulation in the `query_0` column:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from spellchecker import SpellChecker\n",
    "\n",
    "\n",
    "class CorrectQuerySpelling(pt.Transformer):\n",
    "    def __init__(self):\n",
    "        self.spellchecker = SpellChecker()\n",
    "        super().__init__()\n",
    "\n",
    "    def _correct_spelling(self, query: str) -> str:\n",
    "        result = []\n",
    "        for word in query.split(\" \"):\n",
    "            if len(self.spellchecker.unknown([word])) > 0:\n",
    "                result.append(self.spellchecker.correction(word) or word)\n",
    "            else:\n",
    "                result.append(word)\n",
    "        return \" \".join(result)\n",
    "\n",
    "    def transform(self, df: pd.DataFrame) -> pd.DataFrame:\n",
    "        df_new = df.copy()\n",
    "        df_new[\"query_0\"] = df_new[\"query\"]\n",
    "        df_new[\"query\"] = df_new[\"query_0\"].map(self._correct_spelling)\n",
    "        return df_new"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's give it a try:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "correct_query_spelling = CorrectQuerySpelling()\n",
    "correct_query_spelling(queries)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Further reading\n",
    "\n",
    "Check out the sections about the [data model](https://pyterrier.readthedocs.io/en/latest/datamodel.html) and [transformers](https://pyterrier.readthedocs.io/en/latest/transformer.html) in the PyTerrier documentation.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pt",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
